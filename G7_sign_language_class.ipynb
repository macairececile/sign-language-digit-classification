{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language digit classification using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/ardamavi/sign-language-digits-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Recurrent Neural Network for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import imageio\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Preprocess the data as per the given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Write custom dataloader and collate function for creating train dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = '/media/macaire/Ubuntu/Master_2/Neural_Networks/sign-language-digit-classification/Dataset/'\n",
    "\n",
    "class SignDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = self._find_files()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        elements = list(self.image_files.items())\n",
    "        image = io.imread(elements[index][0])\n",
    "        y_label = elements[index][1]\n",
    "        print(image.shape)\n",
    "        return (image, y_label)\n",
    "    \n",
    "    \n",
    "    def _find_files(self):\n",
    "        \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "        files = {}\n",
    "        for i in range(0,9):\n",
    "            images = [f for f in listdir(self.root_dir+'/'+str(i)) if isfile(join(self.root_dir+'/'+str(i), f))]\n",
    "            for el in images:\n",
    "                files[self.root_dir+'/'+str(i)+'/'+el] = i\n",
    "        return files\n",
    "\n",
    "    \n",
    "class SignCollate(object):\n",
    "    \"\"\"Function object used as a collate function for DataLoader.\"\"\"\n",
    "\n",
    "    def __init__(self, ):\n",
    "        \n",
    "        pass\n",
    "        \n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        new_batch = []\n",
    "        for idx in range(len(batch)):\n",
    "            sample = batch[idx][0]\n",
    "            label = batch[idx][1]\n",
    "            new_batch.append(sample)\n",
    "\n",
    "        # scalar output\n",
    "        sample_batch = np.array(new_batch)\n",
    "        sample_batch = torch.FloatTensor(sample_batch)\n",
    "       \n",
    "        return sample_batch\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return self._collate_fn(batch)\n",
    "    \n",
    "\n",
    "dataset = SignDataset(root_dir=path_images)\n",
    "dataset\n",
    "\n",
    "collate_fn = SignCollate()\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# Split into TRAIN and TEST\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "\n",
    "# for x in dataloader:\n",
    "#     print(x.shape)\n",
    "#     x_np = x.numpy()\n",
    "#     plt.imshow(x_np[0][:,:,1])\n",
    "#     plt.show()\n",
    "#     plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define the neural network model in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Define hyperparameters to create instance of neural network model as well as parameters required to train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Write training loop for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Evaluate the model on test data. In this part, it is expected to choose appropriate evaluation metrics based on your task. For an instance, for classification task, accuracy, precision and recall should be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Save the obtained results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
